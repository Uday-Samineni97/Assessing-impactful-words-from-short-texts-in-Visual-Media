{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Assessing short text importance.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ff5116f4d0c8430d8b894f556042cd86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_068da4dac3ab40afba9b87a8296bd723",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c4fb96200ec5411fab76c562dad52801",
              "IPY_MODEL_17531e0d5f1948178459570d266d5eab"
            ]
          }
        },
        "068da4dac3ab40afba9b87a8296bd723": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c4fb96200ec5411fab76c562dad52801": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6bfbf9553c9d4af797eeec4730580957",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 62,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 62,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5dbaa86b70e5429799c781a72e319cd2"
          }
        },
        "17531e0d5f1948178459570d266d5eab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0d8b0583782c40baa19dcbdd0b7bf34e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 62.0/62.0 [00:03&lt;00:00, 17.3B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fe0ca2fec2ac414aa93ba329a91668ce"
          }
        },
        "6bfbf9553c9d4af797eeec4730580957": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5dbaa86b70e5429799c781a72e319cd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0d8b0583782c40baa19dcbdd0b7bf34e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fe0ca2fec2ac414aa93ba329a91668ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fba35075265e4d29bd09678dca04fe46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5897476821064c0cb349a806036fa033",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0c7dd48ccefe42338282645d89fadcbf",
              "IPY_MODEL_c65e58e837364ea3ac8345921d4a6e64"
            ]
          }
        },
        "5897476821064c0cb349a806036fa033": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0c7dd48ccefe42338282645d89fadcbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fb65c21430fe4ab3952b40adc354416e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 479,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 479,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_af17564bd6af45199d290e22ba055bc4"
          }
        },
        "c65e58e837364ea3ac8345921d4a6e64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ac56f33f85f346f68f0ae7702c20cd2d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 479/479 [00:00&lt;00:00, 515B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4a465ea3a73a42a8953e0de03b0dc98e"
          }
        },
        "fb65c21430fe4ab3952b40adc354416e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "af17564bd6af45199d290e22ba055bc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ac56f33f85f346f68f0ae7702c20cd2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4a465ea3a73a42a8953e0de03b0dc98e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "90a94c3f0fac46359f4efd52c74138df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_251fce7c45b84589ae2f10e663de2024",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c1eb9ecb331c44d9ba52c86e37a06a7a",
              "IPY_MODEL_7b1b040e9fa945389a4484962b5b6c75"
            ]
          }
        },
        "251fce7c45b84589ae2f10e663de2024": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c1eb9ecb331c44d9ba52c86e37a06a7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_78d5424b64994fac90ffcfc32f91ddd7",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6f9e6c0fd8b64a2385cd40f5ec3ab8af"
          }
        },
        "7b1b040e9fa945389a4484962b5b6c75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_58e0f52900cf4e19bae43b3ffd7ad8b6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:02&lt;00:00, 112kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_88ff9c8ed4644f49941c3ec700efa832"
          }
        },
        "78d5424b64994fac90ffcfc32f91ddd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6f9e6c0fd8b64a2385cd40f5ec3ab8af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "58e0f52900cf4e19bae43b3ffd7ad8b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "88ff9c8ed4644f49941c3ec700efa832": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fdb976595c2e4969842c5d16a5652467": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_31e2b2c5c7904bb5b94d3ba8cde44580",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9e64c926c3794347a858aed0ad0c456b",
              "IPY_MODEL_77d2ec97bd3d46f79b39c5889b29f1e3"
            ]
          }
        },
        "31e2b2c5c7904bb5b94d3ba8cde44580": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9e64c926c3794347a858aed0ad0c456b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a78eb32f2819499ea8fecf47e9bb7a79",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 112,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 112,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ac6f265183514bb8aec6496ec99875ce"
          }
        },
        "77d2ec97bd3d46f79b39c5889b29f1e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1c4bdf62a1854fb099c23d9e5e751a8b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 112/112 [00:00&lt;00:00, 176B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0ec77b3af2d24a22bc7ffb4630056684"
          }
        },
        "a78eb32f2819499ea8fecf47e9bb7a79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ac6f265183514bb8aec6496ec99875ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1c4bdf62a1854fb099c23d9e5e751a8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0ec77b3af2d24a22bc7ffb4630056684": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7c120f453e1b4f918c6e54f95b92f044": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_593ef8859f5b4775aa02b010afc8e823",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9735d405b55b43e59f2fef275eba439a",
              "IPY_MODEL_b7f16141db62479b94aab16baedd291a"
            ]
          }
        },
        "593ef8859f5b4775aa02b010afc8e823": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9735d405b55b43e59f2fef275eba439a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_549fcef35a4e4ba9946fde34bfbbe437",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440474579,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440474579,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c9f1d52c0090485982561658f24a48da"
          }
        },
        "b7f16141db62479b94aab16baedd291a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a1661ce01bbd4457bd545e00cdbe9190",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:14&lt;00:00, 31.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_91a6fa2913c9488f897eea3647638d05"
          }
        },
        "549fcef35a4e4ba9946fde34bfbbe437": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c9f1d52c0090485982561658f24a48da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a1661ce01bbd4457bd545e00cdbe9190": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "91a6fa2913c9488f897eea3647638d05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8ZnMLXr7qFD",
        "outputId": "75c1ca5a-8d65-4a0b-b5f1-2fe497309411"
      },
      "source": [
        "!pip3 install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.9.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-WJNETf7q2Z"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "class EarlyStopping:\n",
        "    \n",
        "    def __init__(self,path,patience,verbose,delta=0):\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.min_loss = np.Infinity\n",
        "        self.counter = 0\n",
        "    \n",
        "    def __call__(self,validation_loss,model):\n",
        "        validation_score = -validation_loss\n",
        "        \n",
        "        if self.best_score is None:\n",
        "            self.best_score = validation_score\n",
        "            self.save_checkpoint(validation_loss,model)\n",
        "        \n",
        "        elif validation_score < self.best_score + self.delta:\n",
        "            self.counter +=  1\n",
        "            print(f'Early Stopping = {self.counter} of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        \n",
        "        else:\n",
        "            self.best_score = validation_score\n",
        "            self.save_checkpoint(validation_loss,model)\n",
        "            self.counter = 0\n",
        "            \n",
        "    \n",
        "    def save_checkpoint(self,validation_loss,model):\n",
        "        if self.verbose is True:\n",
        "            print(f'Validation loss is ({self.min_loss:.5f} --> {validation_loss:.5f}).  Saving model ...')\n",
        "        torch.save(model, self.path)\n",
        "        self.min_loss = validation_loss\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333,
          "referenced_widgets": [
            "ff5116f4d0c8430d8b894f556042cd86",
            "068da4dac3ab40afba9b87a8296bd723",
            "c4fb96200ec5411fab76c562dad52801",
            "17531e0d5f1948178459570d266d5eab",
            "6bfbf9553c9d4af797eeec4730580957",
            "5dbaa86b70e5429799c781a72e319cd2",
            "0d8b0583782c40baa19dcbdd0b7bf34e",
            "fe0ca2fec2ac414aa93ba329a91668ce",
            "fba35075265e4d29bd09678dca04fe46",
            "5897476821064c0cb349a806036fa033",
            "0c7dd48ccefe42338282645d89fadcbf",
            "c65e58e837364ea3ac8345921d4a6e64",
            "fb65c21430fe4ab3952b40adc354416e",
            "af17564bd6af45199d290e22ba055bc4",
            "ac56f33f85f346f68f0ae7702c20cd2d",
            "4a465ea3a73a42a8953e0de03b0dc98e",
            "90a94c3f0fac46359f4efd52c74138df",
            "251fce7c45b84589ae2f10e663de2024",
            "c1eb9ecb331c44d9ba52c86e37a06a7a",
            "7b1b040e9fa945389a4484962b5b6c75",
            "78d5424b64994fac90ffcfc32f91ddd7",
            "6f9e6c0fd8b64a2385cd40f5ec3ab8af",
            "58e0f52900cf4e19bae43b3ffd7ad8b6",
            "88ff9c8ed4644f49941c3ec700efa832",
            "fdb976595c2e4969842c5d16a5652467",
            "31e2b2c5c7904bb5b94d3ba8cde44580",
            "9e64c926c3794347a858aed0ad0c456b",
            "77d2ec97bd3d46f79b39c5889b29f1e3",
            "a78eb32f2819499ea8fecf47e9bb7a79",
            "ac6f265183514bb8aec6496ec99875ce",
            "1c4bdf62a1854fb099c23d9e5e751a8b",
            "0ec77b3af2d24a22bc7ffb4630056684",
            "7c120f453e1b4f918c6e54f95b92f044",
            "593ef8859f5b4775aa02b010afc8e823",
            "9735d405b55b43e59f2fef275eba439a",
            "b7f16141db62479b94aab16baedd291a",
            "549fcef35a4e4ba9946fde34bfbbe437",
            "c9f1d52c0090485982561658f24a48da",
            "a1661ce01bbd4457bd545e00cdbe9190",
            "91a6fa2913c9488f897eea3647638d05"
          ]
        },
        "id": "FtHRd0Mg7x0W",
        "outputId": "cd2fccfa-0d9c-4ea1-850b-eed62c9f2c6f"
      },
      "source": [
        "#Importing all the necessary packages\n",
        "import torch\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from transformers import AutoTokenizer, AutoModel, BertTokenizer, BertModel\n",
        "import warnings\n",
        "import copy\n",
        "import numpy as np\n",
        "# from earlystopping import EarlyStopping\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "#Defining the tokenizer and pre_trained model \n",
        "#Incase of ERNIE Large Model\n",
        "erine_larg_tok = AutoTokenizer.from_pretrained(\"nghuyong/ernie-2.0-large-en\")\n",
        "erine_larg_mod = AutoModel.from_pretrained('nghuyong/ernie-2.0-large-en')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff5116f4d0c8430d8b894f556042cd86",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=62.0, style=ProgressStyle(description_wâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fba35075265e4d29bd09678dca04fe46",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=479.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "90a94c3f0fac46359f4efd52c74138df",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fdb976595c2e4969842c5d16a5652467",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=112.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7c120f453e1b4f918c6e54f95b92f044",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440474579.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at nghuyong/ernie-2.0-en were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "po91KDGu70rF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "outputId": "2a0e505a-b9a5-4b9c-dfef-d21ba7895278"
      },
      "source": [
        "\n",
        "\n",
        "#Incase of ERNIE Normal Model\n",
        "# erine_small_tok = AutoTokenizer.from_pretrained(\"nghuyong/ernie-2.0-en\")\n",
        "# erine_small_mod = AutoModel.from_pretrained('nghuyong/ernie-2.0-en')\n",
        "\n",
        "#Incase of BERT Normal Uncased Model\n",
        "#bertuc_small_tok = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "#bertuc_small_mod = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "#Incase of BERT Normal Cased Model\n",
        "#bertc_small_tok = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "#bertc_small_mod = BertModel.from_pretrained(\"bert-base-cased\")\n",
        "\n",
        "\n",
        "# Load the train, test and dev dataset\n",
        "def load_dataset(filename):\n",
        "    with open(filename,'r') as fp:\n",
        "        lines = [line.strip() for line in fp]\n",
        "    return lines\n",
        "\n",
        "# Getting the words, pos tags, probablities in a single list from both the Train and Dev dataset\n",
        "def word_traindev_Data(data):\n",
        "    wordLines = data\n",
        "    words = []\n",
        "    probabilities = []\n",
        "    wordList = []\n",
        "    pos = []\n",
        "    empty = []\n",
        "    for line in wordLines:\n",
        "        lineSplit = line.strip().split('\\t')\n",
        "        if line:\n",
        "            word = lineSplit[1]\n",
        "            prob = lineSplit[4]\n",
        "            temp = lineSplit[5]\n",
        "            words.append(word)\n",
        "            probabilities.append(float(prob))\n",
        "            pos.append(temp)\n",
        "        elif not (len(empty) and []):\n",
        "            wordList.append((words, pos, probabilities))\n",
        "            words = []\n",
        "            probabilities = []\n",
        "            pos = []\n",
        "    return wordList\n",
        "\n",
        "# Getting the words in a single list from the Test dataset\n",
        "def word_test_Data(data):\n",
        "    wordLines = data\n",
        "    words = []\n",
        "    testWord = []\n",
        "    empty = []\n",
        "    for line in wordLines:\n",
        "        lineSplit = line.strip().split('\\t')\n",
        "        if line:\n",
        "            word = lineSplit[1]            \n",
        "            words.append(word)\n",
        "        elif not len(empty):\n",
        "            testWord.append(words)\n",
        "            words = []       \n",
        "    return testWord\n",
        "\n",
        "# Generate separate list of words, pos and probablities for Train and Dev data\n",
        "def data_preprocess_train_dev(data):\n",
        "    text = []\n",
        "    pos = []\n",
        "    probs = []\n",
        "    for i,j,k in data:\n",
        "            text.append(i)\n",
        "            pos.append(j)\n",
        "            probs.append(k)\n",
        "    return text,pos, probs\n",
        "\n",
        "# Generate separate list of words for Test data\n",
        "def data_preprocess_test(data):\n",
        "    text = []\n",
        "    for i in data:\n",
        "            text.append(i)\n",
        "    return text\n",
        "\n",
        "# Replicating probablities for matching length incase of sub tokenized words\n",
        "def prob_list(batch_data,batch_probs, tokenizer):\n",
        "    pb = []\n",
        "    for i,j in zip(batch_data,batch_probs):\n",
        "        tp = []\n",
        "        for k,l in zip(i,j):\n",
        "            temp = tokenizer.tokenize(k)\n",
        "            if len(temp) == 1:\n",
        "                tp.append(float(l))\n",
        "            if len(temp) > 1:\n",
        "                for i in range(len(temp)):\n",
        "                    tp.append(float(l))\n",
        "        pb.append(tp)\n",
        "    return pb\n",
        "\n",
        "# Replicating feature vectors for matching length incase of sub tokenized words\n",
        "def feature_list(batch_data,feature, tokenizer):\n",
        "    fv = []\n",
        "    for i,j in zip(batch_data,feature):\n",
        "        tp = []\n",
        "        for k,l in zip(i,j):\n",
        "            temp = tokenizer.tokenize(k)\n",
        "            if len(temp) == 1:\n",
        "                tp.append(l)\n",
        "            if len(temp) > 1:\n",
        "                for i in range(len(temp)):\n",
        "                    tp.append(l)\n",
        "        fv.append(tp)\n",
        "    return fv\n",
        "\n",
        "# Generate sentence from words in dataset\n",
        "def get_sentence(words, tokenizer):    \n",
        "    tokenized_text = []\n",
        "    # tokens=[]\n",
        "    for i in words:\n",
        "        sent = ''\n",
        "        for h in i:\n",
        "            if sent == '':\n",
        "                sent = sent + h\n",
        "            else:\n",
        "                sent = sent+ \" \" +h\n",
        "        # tokens = tokenizer.tokenize(sent)\n",
        "        # print(tokens)\n",
        "        tid = tokenizer.encode(sent, add_special_tokens=False)\n",
        "        tokenized_text.append(tid)\n",
        "    return tokenized_text\n",
        "\n",
        "# function to pad data for equal length\n",
        "def pad_func(data):\n",
        "    max_len = 0\n",
        "    for i in data:\n",
        "        if len(i) > max_len:\n",
        "            max_len = len(i)\n",
        "    if type(i[0]) is list:\n",
        "        padded = [i + [[0, 0, 0, 0, 0, 0]]*(max_len-len(i)) for i in data]\n",
        "    else:\n",
        "        padded = [i + [0]*(max_len-len(i)) for i in data]\n",
        "    return padded\n",
        "\n",
        "#data augmentation function to randomly reverse a sentence, capitalize a word and remove a word from a sentence\n",
        "def data_augment(words, tags, probs):\n",
        "    aug_word_list = []\n",
        "    aug_tag_list = []\n",
        "    aug_prob_list = []\n",
        "    for i in range(len(words)):\n",
        "        aug_word_list.append(words[i])\n",
        "        aug_prob_list.append(probs[i])\n",
        "        aug_tag_list.append(tags[i])\n",
        "        \n",
        "        if (i%2) == 0:\n",
        "            temp_word = copy.copy(words[i])\n",
        "            temp_word.reverse()\n",
        "            aug_word_list.append(temp_word)\n",
        "            \n",
        "            temp_prb = copy.copy(probs[i])\n",
        "            temp_prb.reverse()\n",
        "            aug_prob_list.append(temp_prb)\n",
        "            \n",
        "            temp_tg = copy.copy(tags[i])\n",
        "            temp_tg.reverse()\n",
        "            aug_tag_list.append(temp_tg)\n",
        "            \n",
        "        if (i%3) == 0:\n",
        "            temp_word = copy.copy(words[i])\n",
        "            temp_word[0] = temp_word[0].upper()\n",
        "            aug_word_list.append(temp_word)\n",
        "            \n",
        "            temp_prb = copy.copy(probs[i])\n",
        "            aug_prob_list.append(temp_prb)\n",
        "            \n",
        "            temp_tg = copy.copy(tags[i])\n",
        "            aug_tag_list.append(temp_tg)\n",
        "            \n",
        "        if (i%5) == 0:\n",
        "            temp_word = copy.copy(words[i])\n",
        "            temp_word.remove(temp_word[0])\n",
        "            aug_word_list.append(temp_word)\n",
        "            \n",
        "            \n",
        "            temp_prb = copy.copy(probs[i])\n",
        "            temp_prb.remove(temp_prb[0])\n",
        "            aug_prob_list.append(temp_prb)\n",
        "            \n",
        "            temp_tg = copy.copy(tags[i])\n",
        "            temp_tg.remove(temp_tg[0])\n",
        "            aug_tag_list.append(temp_tg)\n",
        "                \n",
        "    return aug_word_list, aug_prob_list, aug_tag_list\n",
        "\n",
        "#create feature vector for the words based on starts with capital, full word is capital, has hashtags, \n",
        "#word can be tokenized and word that is a connector word\n",
        "def feature_add(trainWords, trainTags, tokenizer):\n",
        "    feature = []\n",
        "    conn = ['a','an','and','the','or','but','yet','on', 'in','of','for','he','she','it','i','.','?','!','have','had','has','her','him','been']\n",
        "    tags = ['NNP','VBN','NNS','NN','VB','PDT','VBD','RB','CB','VBG','CD','JJ']\n",
        "    for i,k in zip(trainWords, trainTags):\n",
        "        temp1 = []\n",
        "        for j,l in zip(i,k):\n",
        "            temp2 =[0] * 6\n",
        "            if j[0].isupper():\n",
        "                temp2[0] = 1.\n",
        "            else:\n",
        "                temp2[0] = 0.\n",
        "            if '##' in j:\n",
        "                temp2[1] = 1.\n",
        "            else:\n",
        "                temp2[1] = 0.\n",
        "            if j.isupper():\n",
        "                temp2[2] = 1.\n",
        "            else:\n",
        "                temp2[2] = 0.\n",
        "            if len(tokenizer.tokenize(j))>1:\n",
        "                temp2[3] = 1.\n",
        "            else:\n",
        "                temp2[3] = 0.\n",
        "            if j.lower() not in conn:\n",
        "                temp2[4] = 1.\n",
        "            else:\n",
        "                temp2[4] = 0.\n",
        "            if l not in tags:\n",
        "                temp2[5] = 0.\n",
        "            else:\n",
        "                temp2[5] = 1.\n",
        "            temp1.append(temp2)\n",
        "        feature.append(temp1)\n",
        "    return feature\n",
        "\n",
        "#function to shuffle the dataset \n",
        "def func_shuffle(tokens, probablities, feature):\n",
        "    mapIndexPosition = list(zip(tokens, probablities, feature))\n",
        "    np.random.shuffle(mapIndexPosition)\n",
        "    tokens, probablities, feature = zip(*mapIndexPosition)\n",
        "    return tokens, probablities, feature\n",
        "\n",
        "# function to get attention mask\n",
        "def gen_attention(data):\n",
        "    attention_mask = []\n",
        "    for i in data:\n",
        "        tmp = list([1] * (np.count_nonzero(i))) + list([0] * (len(i) - (np.count_nonzero(i))))\n",
        "        attention_mask.append(tmp)\n",
        "    return attention_mask\n",
        "\n",
        "#getting tokens, features and probablities\n",
        "def get_parts_data(Words, Tags, Labels, tokenizer):\n",
        "    tokens = get_sentence(Words, tokenizer)\n",
        "    probablities = prob_list(Words,Labels, tokenizer)\n",
        "    features = feature_add(Words, Tags, tokenizer)\n",
        "    feature = feature_list(Words,features, tokenizer)\n",
        "    tokens, probablities, feature = func_shuffle(tokens, probablities, feature)\n",
        "    tokens_pad = pad_func(tokens)\n",
        "    probablities_pad = pad_func(probablities)\n",
        "    feature_pad = pad_func(feature)\n",
        "    attention_pad = gen_attention(tokens_pad)\n",
        "    return tokens_pad, probablities_pad, feature_pad, attention_pad\n",
        "\n",
        "#Function for getting first 4 emphasized words\n",
        "#Done by Phani\n",
        "def finalProbs(data,values):        \n",
        "    temp_list = [list(x) for x in zip(data,values)]\n",
        "    sentence_list = []\n",
        "    probas_list = []\n",
        "    for sentences,probas in temp_list:\n",
        "        sentence_list.append([[list] for list in sentences])\n",
        "        probas_list.append([prob for prob in probas])\n",
        "\n",
        "    wordsFinal = []\n",
        "    probFinal = []\n",
        "    temp2 = []\n",
        "    for word, prob in zip(sentence_list,probas_list):\n",
        "        wordList = []\n",
        "        probList = []\n",
        "        for i,j in zip(word,prob):\n",
        "            if not(i[0].startswith(\"##\")):\n",
        "                wordList.append(i)\n",
        "                probList.append(j)\n",
        "            else:\n",
        "                wordTemp = wordList[-1]+[i[0]]\n",
        "                probTemp = probList[-1]+[j[0]]\n",
        "                wordTemp = [''.join(wordTemp)]\n",
        "                wordList.append(wordTemp)\n",
        "                probList.append(probTemp)\n",
        "                del(wordList[-2])\n",
        "                del(probList[-2])\n",
        "      \n",
        "        for k in probList:\n",
        "            if len(k) == 1:\n",
        "                temp2.append(k)\n",
        "            else:\n",
        "                average = [np.average(k)]\n",
        "                temp2.append(average)\n",
        "        wordsFinal.append(wordList)\n",
        "        probFinal.append(temp2)\n",
        "        wordList = []\n",
        "        probList = []\n",
        "        temp2 = []\n",
        "    return wordsFinal,probFinal\n",
        "\n",
        "def compute_loss(i):\n",
        "    wlist = []\n",
        "    plist = []\n",
        "    for j in i:\n",
        "        wlist.append(j[0])\n",
        "        plist.append(j[1])\n",
        "        wtemp = []\n",
        "        ptemp = []\n",
        "    for i,j in sorted(zip(plist,wlist),reverse = True):\n",
        "        wtemp.append(j)\n",
        "        ptemp.append(i)\n",
        "        \n",
        "    wfinal = []\n",
        "    loss = []\n",
        "    finalList = []\n",
        "    for i,j in zip(wtemp,ptemp):\n",
        "        for k,l in zip(wtemp[1:],ptemp[1:]):\n",
        "            currentWord = i[0]\n",
        "            currentProb = float(j[0])\n",
        "            nextprob = float(l[0])\n",
        "            temp = currentProb - nextprob\n",
        "            lossTemp = -max((temp),0) * math.log1p(temp)\n",
        "            loss.append(lossTemp)\n",
        "        wfinal.append([[currentWord],[currentProb],[np.average(loss)]])\n",
        "    finalList.append(wfinal)\n",
        "    \n",
        "    return finalList\n",
        "\n",
        "def final_rank(words,probs):\n",
        "    loss_test = [] \n",
        "    for i,j in zip(words,probs):\n",
        "        loss_temp = []\n",
        "        for k,l in zip(i,j):\n",
        "            if '##' in k[0]:\n",
        "                loss_temp.append([k,l])\n",
        "        if loss_temp is []:\n",
        "            loss_temp.append('[]')\n",
        "        loss_test.append(loss_temp)\n",
        "    \n",
        "    \n",
        "    subword_dict = []\n",
        "    subword_list = []\n",
        "    for i in loss_test:\n",
        "        empty_dict = dict.fromkeys(['Rank1','Rank2','Rank3','Rank4'])\n",
        "        if (i == []):\n",
        "            subword_list.append([[\"No subwords\"]])\n",
        "            subword_dict.append(empty_dict)\n",
        "            continue\n",
        "        else:\n",
        "            if (len(i) == 1):\n",
        "                subword_list.append(i)\n",
        "                for a in i:\n",
        "                    empty_dict['Rank1'] = a[0]\n",
        "                subword_dict.append(empty_dict)\n",
        "            else:\n",
        "                j = compute_loss(i)\n",
        "                subword_list.append(j)\n",
        "                for c in j:\n",
        "                    for d in c:\n",
        "                        if empty_dict['Rank1'] is None:\n",
        "                            empty_dict['Rank1'] = d[0]\n",
        "                        elif empty_dict['Rank2'] is None:\n",
        "                             empty_dict['Rank2'] = d[0]\n",
        "                        elif empty_dict['Rank3'] is None:\n",
        "                            empty_dict['Rank3'] = d[0]\n",
        "                        else:\n",
        "                            empty_dict['Rank4'] = d[0]\n",
        "                subword_dict.append(empty_dict)\n",
        "                \n",
        "    wd = []\n",
        "    for i,j in zip(words,probs):\n",
        "        dic = sorted(zip(j,i),reverse=True)\n",
        "        wd.append(dic)\n",
        "        word_dict = []    \n",
        "    for i,k in zip(wd,subword_dict):\n",
        "        empty_word_dict = dict.fromkeys(['Rank1','Rank2','Rank3','Rank4'])\n",
        "        for j in i:\n",
        "            if '##' not in j[1][0]:\n",
        "                if empty_word_dict['Rank1'] is None:\n",
        "                    empty_word_dict['Rank1'] = j[1]\n",
        "                elif empty_word_dict['Rank2'] is None:\n",
        "                    empty_word_dict['Rank2'] = j[1]\n",
        "                elif empty_word_dict['Rank3'] is None:\n",
        "                    empty_word_dict['Rank3'] = j[1]\n",
        "                elif empty_word_dict['Rank4'] is None:\n",
        "                    empty_word_dict['Rank4'] = j[1]\n",
        "        word_dict.append(empty_word_dict)\n",
        "    \n",
        "    \n",
        "    final_word_dict = []\n",
        "    for i,j in zip(subword_dict,word_dict):\n",
        "        final_word_dict.append((i,j))\n",
        "    return final_word_dict\n",
        "\n",
        "\n",
        "#defining the model class\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, pre_trained_model, tokenizer, layers, dropout):\n",
        "        super(Model, self).__init__()\n",
        "        self.model = pre_trained_model\n",
        "        self.tokenize = tokenizer\n",
        "        self.linear = nn.Linear(layers, 1)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, words, tags, labels):\n",
        "        tokens, probablities, feature, attention = get_parts_data(words, tags, labels, self.tokenize)\n",
        "        output = self.model(torch.tensor(tokens), torch.tensor(attention))        \n",
        "        final_op = torch.cat((output[0], torch.tensor(feature)),dim=-1)\n",
        "        linear_output = self.linear(final_op)\n",
        "        output = self.dropout(linear_output)\n",
        "        proba = self.sigmoid(output)\n",
        "        return proba, probablities\n",
        "\n",
        "# Specifying file names\n",
        "TRAINING_FILE = \"drive/MyDrive/Emphasis-Selection-for-Written-Text-in-Visual-Media-main/train.txt\"\n",
        "DEV_FILE = \"drive/MyDrive/Emphasis-Selection-for-Written-Text-in-Visual-Media-main/dev.txt\"\n",
        "TEST_FILE = \"drive/MyDrive/Emphasis-Selection-for-Written-Text-in-Visual-Media-main/test.txt\"\n",
        "\n",
        "# Preprocessing work on the dataset \n",
        "trainText = word_traindev_Data(load_dataset(TRAINING_FILE))\n",
        "testEval = word_test_Data(load_dataset(TEST_FILE))\n",
        "devText = word_traindev_Data(load_dataset(DEV_FILE))\n",
        "\n",
        "trainWords,trainTags, trainLabels = data_preprocess_train_dev(trainText)\n",
        "devWords, devTags, devLabels = data_preprocess_train_dev(devText)\n",
        "testWords = data_preprocess_test(testEval)\n",
        "\n",
        "#augmenting the dataset size\n",
        "trainWords, trainLabels, trainTags = data_augment(trainWords, trainTags, trainLabels)\n",
        "\n",
        "layers = 1030\n",
        "dropout = 0.2\n",
        "\n",
        "tokenizer = erine_larg_tok\n",
        "pretrained = erine_larg_mod\n",
        "\n",
        "model = Model(pretrained, tokenizer, layers, dropout)\n",
        "\n",
        "model_path = 'bert_no_aug.pth'\n",
        "early_stopping = EarlyStopping(model_path ,4,True)\n",
        "optimizer = optim.Adamax(model.parameters(), lr=0.001)\n",
        "loss_func = nn.MSELoss(reduction = 'mean')\n",
        "\n",
        "batch = 100\n",
        "folds = 5\n",
        "epoch = 6\n",
        "\n",
        "combined_data = trainWords\n",
        "combined_tags = trainTags\n",
        "combined_labels = trainLabels\n",
        "data = np.asarray(combined_data)\n",
        "tags = np.asarray(combined_tags)\n",
        "labels = np.asarray(combined_labels)\n",
        "kf = KFold(n_splits=folds, random_state=0, shuffle=True)\n",
        "\n",
        "for epoch_num in range(epoch):\n",
        "    print(\"\\nRunning epoch ---->{}\".format(epoch_num))\n",
        "    count = 0\n",
        "    fold_training_loss = []\n",
        "    fold_validation_loss = []\n",
        "    \n",
        "    # Dividing data into folds\n",
        "    for train_index, test_index in kf.split(data, tags, labels):\n",
        "        model.train()\n",
        "        count = count + 1\n",
        "        train_words = data[train_index]\n",
        "        dev_words = data[test_index]\n",
        "        train_tags = tags[train_index]\n",
        "        dev_tags = tags[test_index]\n",
        "        train_labels = labels[train_index]\n",
        "        dev_labels = labels[test_index]\n",
        "        training_loss = []\n",
        "        validation_loss = []\n",
        "        \n",
        "        # Training the model\n",
        "        for i in range(0, len(train_words), batch):\n",
        "            model.zero_grad()           \n",
        "            train_probas, train_probablities_pad = model(train_words[i:i+batch], train_tags[i:i+batch], train_labels[i:i+batch])            \n",
        "            train_grd_truth = []\n",
        "            for i in train_probablities_pad:                \n",
        "                p = []\n",
        "                for j in i:\n",
        "                    q=[]\n",
        "                    q.append(j)\n",
        "                    p.append(q)\n",
        "                train_grd_truth.append(p)\n",
        "            train_batch_loss = loss_func(train_probas, torch.tensor(train_grd_truth))\n",
        "            training_loss.append(train_batch_loss.item())\n",
        "            train_batch_loss.backward()\n",
        "            optimizer.zero_grad()\n",
        "            optimizer.step()\n",
        "                    \n",
        "        #Validation Run\n",
        "        with torch.no_grad():\n",
        "            for i in range(0, len(dev_words), batch):\n",
        "                dev_probas, dev_probablities_pad = model(dev_words[i:i+batch], dev_tags[i:i+batch], dev_labels[i:i+batch])\n",
        "                dev_grd_truth = []\n",
        "                for i in dev_probablities_pad:\n",
        "                    p = []\n",
        "                    for j in i:\n",
        "                        q=[]\n",
        "                        q.append(j)\n",
        "                        p.append(q)\n",
        "                    dev_grd_truth.append(p)\n",
        "                dev_batch_loss = loss_func(dev_probas, torch.tensor(dev_grd_truth))\n",
        "                validation_loss.append(dev_batch_loss.item())\n",
        "                \n",
        "        fold_training_loss.append(np.average(training_loss))\n",
        "        fold_validation_loss.append(np.average(validation_loss))\n",
        "    print(\"Training loss for 8 fold = {}\".format(fold_training_loss))\n",
        "    print(\"Validation loss for 8 fold = {}\".format(fold_validation_loss))\n",
        "        \n",
        "    print(\"Epoch {} Training loss ---->{}\".format(epoch_num,(np.average(fold_training_loss))))\n",
        "    print(\"Epoch {} Validation loss ---->{}\".format(epoch_num,(np.average(fold_validation_loss))))\n",
        "\n",
        "    early_stopping(np.average(fold_validation_loss), model)\n",
        "    if early_stopping.early_stop is True:\n",
        "        print(\"Early stopping\")\n",
        "        break\n",
        "\n",
        "#loading the trained model\n",
        "model = torch.load(model_path)\n",
        "\n",
        "#Calculating the loss for test data\n",
        "test_loss = []\n",
        "pred_prob = []\n",
        "batch = 392\n",
        "with torch.no_grad():\n",
        "    for i in range(0, len(devWords), batch):\n",
        "        test_probas, test_probablities_pad = model(devWords[i:i+batch], devTags[i:i+batch], devLabels[i:i+batch])\n",
        "        test_grd_truth = []\n",
        "        pred_prob = test_probas.detach().numpy()\n",
        "        for i in test_probablities_pad:\n",
        "            p = []\n",
        "            for j in i:\n",
        "                q=[]\n",
        "                q.append(j)\n",
        "                p.append(q)\n",
        "            test_grd_truth.append(p)\n",
        "        test_batch_loss = loss_func(test_probas, torch.tensor(test_grd_truth))\n",
        "        test_loss.append(test_batch_loss.item())               \n",
        "print(\"Test loss ----> {}\".format(np.average(test_loss)))\n",
        "\n",
        "test_prob = []\n",
        "for w,x in zip(devWords,pred_prob):\n",
        "    out = w \n",
        "    temp_ans = []\n",
        "    index = 0\n",
        "    for i in out:\n",
        "        if (len(tokenizer.tokenize(i))) == 1:\n",
        "            temp_ans.append(x[index][0])\n",
        "            index = index + 1\n",
        "        else:\n",
        "            holder = []\n",
        "            for j in range(len(tokenizer.tokenize(i))):\n",
        "                holder.append(x[index][0])\n",
        "                index = index + 1\n",
        "            prb = np.average(holder)\n",
        "            temp_ans.append(prb) \n",
        "    test_prob.append(temp_ans)\n",
        "\n",
        "x = []\n",
        "y = []\n",
        "for i,j in zip(test_prob, devLabels):\n",
        "    for k,l in zip(i,j):\n",
        "        x.append(k)\n",
        "        y.append(l)\n",
        "score = mean_absolute_error(y,x)\n",
        "\n",
        "top3_words = []\n",
        "top3_ground_words = []\n",
        "\n",
        "\n",
        "for pred,actual,words in zip(test_prob, devLabels, devWords):\n",
        "    order_temp = [i for _,i in sorted(zip(actual,words), reverse = True)]\n",
        "    top3_ground_words.append(order_temp[:5])\n",
        "    order_pred_temp = [i for _,i in sorted(zip(pred,words), reverse = True)]\n",
        "    top3_words.append(order_pred_temp[:5])\n",
        "    \n",
        "def intersection(lst1, lst2): \n",
        "    lst3 = [value for value in lst1 if value in lst2] \n",
        "    return lst3\n",
        "\n",
        "def match(top3_words, top3_ground_words):\n",
        "    scores = []\n",
        "    topk = 5\n",
        "    dataset = len(top3_words)\n",
        "    for i in range(len(top3_words)):\n",
        "       intersect = intersection(top3_words[i], top3_ground_words[i])\n",
        "       score_temp = (len(intersect))/topk\n",
        "       scores.append(score_temp)\n",
        "    scores_final = np.sum(scores)\n",
        "    match = scores_final/dataset\n",
        "    return match\n",
        "\n",
        "final_score = match(top3_words,top3_ground_words)\n",
        "print(\"loss score of MAE:\",score)\n",
        "print(\"final score of the match metric:\",final_score)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Running epoch ---->0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-332e8944ccd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mtrain_probas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_probablities_pad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_words\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_tags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0mtrain_grd_truth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_probablities_pad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-332e8944ccd7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, words, tags, labels)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0mfinal_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m         \u001b[0mlinear_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1845\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (2700x774 and 1030x1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFl7Elo48pTU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}